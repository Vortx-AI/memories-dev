# ğŸ§  memories-dev Core Module

<div align="center">

[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)
[![License: Apache-2.0](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)
[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)
[![Tests](https://github.com/Vortx-AI/memories-dev/actions/workflows/tests.yml/badge.svg)](https://github.com/Vortx-AI/memories-dev/actions/workflows/tests.yml)

**Building the World's Memory for Artificial General Intelligence**

</div>

> Collective AGI memory - v2.0.4 (Scheduled for March 3, 2025)

## ğŸ“‹ Release Timeline
- **v1.0.0** - Released on February 14, 2025: Initial stable release with core functionality
- **v2.0.4** - Scheduled for March 3, 2025: Current development version with enhanced features

## ğŸŒŸ What's New in Version 2.0.4

### New Features
- **Enhanced Data Sources**: Complete integration with Overture Maps and OpenStreetMap
- **Multi-model Inference**: Compare results from multiple LLM providers
- **Streaming Responses**: Real-time streaming for all supported model providers
- **Memory Optimization**: Advanced memory usage with automatic tier balancing
- **Distributed Memory**: Support for distributed memory across multiple nodes

### Improvements
- **Data Acquisition**: Multi-source fusion and temporal analysis capabilities
- **Model Integration**: Function calling support and improved caching
- **Memory Management**: Intelligent compression and migration policies
- **Deployment Options**: Enhanced standalone, consensus, and swarmed deployments
- **Documentation**: Comprehensive examples and real-world use cases

## ğŸš€ Overview

memories-dev is a comprehensive Python library for building and managing collective AGI memory systems using satellite imagery, vector data, and large language models. It provides a robust architecture for memory formation, retrieval, and synthesis across multiple modalities, enabling AI models to maintain and utilize contextual understanding across interactions.

### ğŸ¯ Key Goals
- Enable persistent memory for AI systems
- Provide context-aware intelligence
- Support multi-modal memory integration
- Ensure scalable and efficient memory operations
- Maintain privacy and security in memory access

## ğŸ’» Quick Start

```python
from memories import MemorySystem
from memories.models import LoadModel
from memories.data_acquisition import DataManager

# Initialize components
memory_system = MemorySystem(
    store_type="vector",  # Options: "vector", "graph", "hybrid"
    vector_store="milvus",
    embedding_model="text-embedding-3-small"
)

data_manager = DataManager(cache_dir="./data_cache")
model = LoadModel(
    model_provider="openai",
    deployment_type="api",
    model_name="gpt-4"
)

# Define area of interest
bbox = {
    'xmin': -122.4018,
    'ymin': 37.7914,
    'xmax': -122.3928,
    'ymax': 37.7994
}

# Get satellite and vector data
satellite_data = await data_manager.get_satellite_data(
    bbox_coords=bbox,
    start_date="2023-01-01",
    end_date="2023-01-31"
)

vector_data = await data_manager.get_vector_data(
    bbox=bbox,
    layers=["buildings", "roads", "landuse"]
)

# Store a memory with multi-modal data
memory_id = memory_system.store(
    content={
        "satellite_imagery": satellite_data,
        "vector_features": vector_data,
        "text_description": "Urban area with mixed residential and commercial buildings"
    },
    metadata={
        "location": bbox,
        "timestamp": "2025-02-15T10:30:00Z",
        "source": "satellite_analysis"
    }
)

# Query memories with context
relevant_memories = memory_system.query(
    query="What is the building density in this urban area?",
    location=bbox,
    time_range=("2025-01-01", "2025-02-15")
)

# Generate insights with LLM
prompt = f"Analyze this location with the following data: {satellite_data}, {vector_data}, {relevant_memories}"
insights = model.get_response(prompt)
print(insights["text"])

# Clean up
model.cleanup()
```

## ğŸ—ï¸ Installation

### Standard Installation
```bash
# Basic installation
pip install memories-dev

# With GPU support
pip install memories-dev[gpu]

# Full installation with all features
pip install memories-dev[all]
```

### Development Installation
```bash
# Clone repository
git clone https://github.com/Vortx-AI/memories-dev.git
cd memories-dev

# Install development dependencies
pip install -e ".[dev]"

# Install documentation tools
pip install -e ".[docs]"
```

## ğŸ”§ System Requirements

### Minimum (Development)
- Python 3.9+
- 16GB RAM
- 4+ CPU cores
- 20GB storage
- Docker & Docker Compose (for local development)

### Production (Recommended)
- 32GB+ RAM
- 8+ CPU cores
- NVIDIA GPU with 8GB+ VRAM
- 100GB+ SSD storage
- Kubernetes cluster for distributed deployment

## ğŸ“Š Monitoring & Observability

### Available in v2.0.4
- Comprehensive logging system with structured output
- Memory operation metrics with Prometheus integration
- Performance tracking for core operations
- Health check endpoints
- Grafana dashboards for memory metrics
- Real-time memory operation monitoring
- Advanced performance analytics
- Automated alerting system

## ğŸ“ Project Structure

```
memories/
â”œâ”€â”€ core/            # Core memory system
â”‚   â”œâ”€â”€ memory_manager.py # Memory management
â”‚   â””â”€â”€ policies.py # Memory policies
â”‚
â”œâ”€â”€ data_acquisition/ # Data Collection
â”‚   â”œâ”€â”€ sources/     # Data sources
â”‚   â”‚   â”œâ”€â”€ sentinel_api.py # Sentinel-2
â”‚   â”‚   â”œâ”€â”€ landsat_api.py # Landsat
â”‚   â”‚   â”œâ”€â”€ osm_api.py # OpenStreetMap
â”‚   â”‚   â”œâ”€â”€ overture_api.py # Overture Maps
â”‚   â”‚   â”œâ”€â”€ wfs_api.py # WFS
â”‚   â”‚   â””â”€â”€ planetary_compute.py # Planetary Computer
â”‚   â”œâ”€â”€ processing/ # Data processing
â”‚   â”‚   â”œâ”€â”€ cloud_mask.py # Cloud masking
â”‚   â”‚   â”œâ”€â”€ indices.py # Spectral indices
â”‚   â”‚   â”œâ”€â”€ fusion.py # Data fusion
â”‚   â”‚   â””â”€â”€ validation.py # Data validation
â”‚   â””â”€â”€ data_manager.py # Data management
â”‚
â”œâ”€â”€ models/          # AI Models
â”‚   â”œâ”€â”€ base_model.py # Base model implementation
â”‚   â”œâ”€â”€ load_model.py # Model loader
â”‚   â”œâ”€â”€ api_connector.py # API connectors
â”‚   â”œâ”€â”€ streaming.py # Streaming responses
â”‚   â”œâ”€â”€ caching.py # Response caching
â”‚   â”œâ”€â”€ function_calling.py # Function calling
â”‚   â””â”€â”€ multi_model.py # Multi-model inference
â”‚
â””â”€â”€ deployments/     # Deployment options
    â”œâ”€â”€ standalone/ # Standalone deployment
    â”œâ”€â”€ consensus/ # Consensus deployment
    â””â”€â”€ swarmed/ # Swarmed deployment
```

## ğŸ§© Core Components

### 1. ğŸ“¡ Data Acquisition
Handles multi-modal data ingestion from various sources including satellite imagery, vector data, and environmental metrics.

### 2. ğŸ§  Memory Management
Provides tiered memory storage with hot, warm, and cold tiers for efficient data access and storage optimization.

### 3. ğŸ¤– Model Integration
Supports multiple model providers with both local deployment and API-based access options.

### 4. ğŸš€ Deployment
Offers flexible deployment options including standalone, consensus-based, and swarmed architectures.

## ğŸ“š Documentation

For more detailed information, check out our documentation:

- [Quick Start Guide](https://memories-dev.readthedocs.io/quickstart.html)
- [User Guide](https://memories-dev.readthedocs.io/user_guide/index.html)
- [API Reference](https://memories-dev.readthedocs.io/api_reference/index.html)
- [Examples](https://memories-dev.readthedocs.io/user_guide/examples.html)
- [Development Guide](https://memories-dev.readthedocs.io/development/index.html)

<p align="center">Built with ğŸ’œ by the memories-dev team</p>
